---
title: "Персоналии"
subtitle: "Расскажем о героях повести."
format: html
warning: FALSE
editor: visual
---

<br/>

## Имена собственные

<br/> 
В начале исследования с помощью аннотированных данных были выбраны  все имена собственные.

```{r}
library(tidyverse)
library(rvest)
library(tidytext)
library(tokenizers)
library(udpipe)
library(dplyr)
library(ggplot2)
library(wordcloud)
library(readr)

# Загружаем тибл, полученный на прошлом этапе исследования.
all_roza_ann_tbl <- read.csv("docs/all_roza_ann_tbl.csv")

# Находим все имена собственные в аннотированном тексте, считаем леммы
propn_list <- all_roza_ann_tbl |>
  filter(upos == "PROPN") |> 
  filter(str_detect(feats, "Animacy=Inan")) |> 
  count(lemma) |> 
  arrange(-n)

# Выводим топ-10 самых частых лемм с признаками Animacy=Inan
head(propn_list, 20)

```


Мы получили неопрятный список географических названий и имен.Даже поверхностный анализ данных показал, что лемматизация дала много ошибочных результатов. Исходный текст изобилует опечатками, вариантами написания имен, уменьшительно-ласкательными формами. Вернувшись на этап "чистки" данных, к проблемных именам были добавлены "маркеры" (Например, "DZIO_" или "NIU_"). Дальше вручную был составлен список упоминавшихся имен и собраны данные. 

```{r}
# Посчитаем упоминаемых персон (+МАРКЕРЫ)
persona2_qty <- all_roza_ann_tbl |> 
  filter(lemma == "Клара" | lemma == "ROZA_Роз" | lemma == "NIU_Ниуниу" 
         | lemma == "Цеткин" | lemma == "MATILDA_Матильд" | lemma == "Дифенбах"
         | lemma == "Люксембург" | lemma == "DZIO_Дцио" | lemma == "Вронка"
         | lemma == "Меринг" | lemma == "MATILDA_Матильда"| lemma == "Бебель" 
         | lemma == "дорогой" | lemma == "сон" | lemma == "Гертруд" 
         | lemma == "Либкнехта" | lemma == "Парвус" | lemma == "Вурм"
         | lemma == "Розенфельд" | lemma == "KOSTYA_Кость" | lemma == "ROZA_Розин"
         | lemma == "YuYu_Юя" | lemma == "Карл" | lemma == "Толст"
         | lemma == "ROZA_Роза" | lemma == "Марта" | lemma == "Пауль"
         | lemma == "Троиц" | lemma == "Фаисст" | lemma == "Ханс"
         | lemma == "KOSTYA_Кост" | lemma == "Розенталь" | lemma == "ROZA_Розино"
         | lemma == "DZIO_Циу" | lemma == "LULU_Лул" | lemma == "NIU_Ниуниус" 
         | lemma == "ROZA_роз" | lemma == "Бах" | lemma == "Берндштейн"
         | lemma == "Турнер" | lemma == "Бы" | lemma == "Гольдберг" 
         | lemma == "Дорогуль" | lemma == "Каролус" | lemma == "Мария" 
         | lemma == "Мёрика" | lemma == "Рикарда" | lemma == "Роберт" 
         | lemma == "Соня" | lemma == "NIU_Ниуниа" | lemma == "YuYu_Ююк" 
         | lemma == "Августина" | lemma == "Боутен" | lemma == "Веггис" 
         | lemma == "Вильгельм" | lemma == "	Вронкэ" | lemma == "Голсуорси" 
         | lemma == "Грефенсберг" | lemma == "Ид" | lemma == "Каспрзак" 
         | lemma == "Каутский" | lemma == "Кольберг" | lemma == "	Луиза" 
         | lemma == "Максим" | lemma == "Моцарт" | lemma == "Н" 
         | lemma == "Р" | lemma == "Струв" | lemma == "Тильд" 
         | lemma == "Феликс" | lemma == "Форст" | lemma == "Цитц" 
         | lemma == "Шёнеберг" | lemma == "Эбенхаузен" | lemma == "**Парвус" 
         | lemma == "*ROZA_Розино" | lemma == "KOSTYA_Костик" 
         | lemma == "LULU_лул" | lemma == "NIU_Ниунисия" | lemma == "NIU_Ниуниуш" 
         | lemma == "ROZA_Розе" | lemma == "ROZA_Розина" | lemma == "ROZA_Розины" 
         | lemma == "YuYu_Ююзия" | lemma == "Анна" | lemma == "Бернштейн" 
         | lemma == "К." | lemma == "Лигниц" | lemma == "Ми" | lemma == "Нинуниу" 
         | token == "Мими" | lemma == "Юю") |> 
  select(doc_id, lemma, token, upos, feats) |>
  count(lemma, sort = TRUE)

head(propn_list, 20)

```


Подробнее о нескольких из упоминаемых персоналий.

<br/>

## Лео Йогишес

<br/>

1. *DZIO_ДзиоДзио.* [Позже добавлю фото и биографию].

```{r}
#Лео Йогишес

yogishes_qty <- all_roza_ann_tbl |> 
filter(lemma == "йогишес" | lemma == "Йогишес" 
         | lemma == "иогишес" | lemma == "иогихес"
         | lemma == "Лео" | lemma == "лео") |> 
  # select(doc_id, lemma, token, upos, feats) |> 
  select(lemma, token)

# он же, но уже под другим именем 
dzio_qty <- all_roza_ann_tbl |> 
  filter(str_detect(lemma, "DZIO_")) |> 
  # select(doc_id, lemma, token, upos, feats)
  select(lemma, token)

# объединяем Лео
leo_yogishes_qty <- bind_rows(
  yogishes_qty,
  dzio_qty
)

unique(leo_yogishes_qty$token)

# Сортируем имена Лео Йогишеса по частоте использования в повести.

leo_yogishes_qty |> 
  count(token) |>  # Считаем token
  arrange(desc(n))  

```
<br/>

## Костя Цеткин

<br/>

2. *NIU_Ниуниу* [Позже добавлю фото и биографию].

```{r}
# Ищем Костю Цеткина
kostya_qty <- all_roza_ann_tbl |> 
  filter(str_detect(lemma, "KOSTYA_")) |> 
  # select(doc_id, lemma, token, upos, feats) |> 
  select(lemma, token)

# он же
niu_qty <- all_roza_ann_tbl |> 
  filter(str_detect(lemma, "NIU_")) |> 
  # select(doc_id, lemma, token, upos, feats)|>
  select(lemma, token)

# объединяем Костю
kostya_tsetkin_qty <- bind_rows(
  kostya_qty,
  niu_qty
  )

unique(kostya_tsetkin_qty$token)


# Есть ошибки присвоения маркеров, но их доля невелика
kostya_tsetkin_qty |> 
  count(token) |>  # Считаем token
  arrange(desc(n))  

```
<br/>

## Мими

<br/>

3. Загадочная *Мими.* При лемматизации эта Мими упорно превращалась в слово "мой". Заглянула в тексты, где она упоминается - выходило, что это какое-то животное? Обратим на нее внимание! Продолжение ее истории дальше.

```{r}
# Ищем собачку/кошечку Мими, лемматизированную как "мой"
mimi_qty <- all_roza_ann_tbl |> 
  filter(str_detect(lemma, "MIMI_")) |> 
  select(doc_id, lemma, token, upos, feats)

mimi_qty |> 
  count(token) |>  # Считаем token
  arrange(desc(n)) 

```

